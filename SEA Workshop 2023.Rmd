---
title:
subtitle: 
author:
date:
output:
  html_document:
    toc: false
    toc_float: true 
    depth: 2
    number_sections: false
    theme: spacelab
    highlight: pygments
editor_options: 
  markdown: 
    wrap: 150
---

```{r, echo=FALSE}
htmltools::img(src =knitr::image_uri('images/banner1.png'),
               alt = 'logo', 
               style = 'position:center; top:0; left:0; padding:0px;')
```

------------------------------------------------------------------------------------------------------------------------------------------------------

# SEA Shark and Ray Research and Conservation Workshop {.tabset .tabset-fade}

<br>

## Introductions



:::: {style="display: grid; grid-template-columns: 2fr 1fr; grid-column-gap: 60px;"}

::: {}


### Who am I?

<br>

**Vinay** is a Research Scientist at the [Australian Institute of Marine Science](https://www.aims.gov.au/). He is an ecologist that is particularly
interested in using spatio-temporal datasets to understand animal movements and distributions patterns. He has considerable experience using **R** to
analyse and visualise large and complex spatial datasets. He has developed **R** code and packages to analyse 2 and 3 dimensional movement patterns of
animals using acoustic telemetry data from single study sites to continental scale arrays. Vinay's **R** codes can be found on his [github
page](https://github.com/vinayudyawer).


:::

::: {}

![](images/pic.jpg) 

:::

::::


<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------

### Course outline

**In this course you will learn about different ways to analyse and interpret your aquatic telemetry datasets using R**. This workshop will
demonstrate how **R** can make the processing of spatial data much quicker and easier than using standard GIS software! At the end of this workshop
you will also have the annotated **R** code that you can re-run at any time, share with collaborators and build on with those newly acquired data!

I designed this course not to comprehensively cover all the tools in **R**, but rather to give you an understanding of options on how to analyse your
telemetry data (both from satellite and acoustic tags). Every new project comes with its own problems and questions and you will need to be
independent, patient and creative to solve these challenges. It makes sense to invest time in becoming familiar with **R**, because today **R** is the
leading platform for environmental data analysis and has some other functionalities which may surprise you!

<br>

This **R** workshop is intended to run across 3 sessions.

<br>

-   **Session 1:** *Getting familiar with R and spatial data*

1.  A brief introduction to **R**
2.  **Import** and **explore** datasets using %pipes% and the [*tidyverse*](http://tidyverse.org/) group of **R** packages
3.  Working with **Spatial objects** using the [*sf*](https://r-spatial.github.io/sf/) **R** package
4.  Generating interactive maps using [*mapview*](https://r-spatial.github.io/mapview/)

<br>

-   **Session 2:** *Working with satellite telemetry data*

1.  Understanding the data structure from **satellite tags**
2.  **Processing** satellite tag data using the [*aniMotum*](https://github.com/ianjonsen/aniMotum) package
3.  **Visualising** satellite tag data using the [*ggspatial*](https://paleolimbot.github.io/ggspatial/) package

<br>

-   **Session 3:** *Working with passive acoustic telemetry data*

1.  Understanding the data structure from **acoustic telemetry data**
2.  Using the [*VTrack*](http://github.com/rossdwyer/VTrack) R package to explore patterns in animal detections and dispersal
3.  Using the [*re**mo**ra*](https://github.com/IMOS-AnimalTracking/remora) R package to interactively explore your telemetry data


<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------

### Course Resources

The course resources will be emailed to you prior to the workshop. However, you can also access the data and scripts we will work through in this
course, download the course resources from this [GitHub repository](https://github.com/vinayudyawer/SEA-workshop2023) page. This page contains the
course documents, telemetry example data and R scripts we are going to work with. To download the folder click on the green
[**Code**]{style="color:green"}, dropdown menu and select **"Download ZIP"**

![](Images/github.png)

<br><br><br><br>

------------------------------------------------------------------------------------------------------------------------------------------------------

## Session 1

### Getting familiar with R and spatial data

|                           |
|:--------------------------|
| ![](images/blacktip.png) |

<br><br>

#### 1.1 A brief Introduction to **R**

The process of turning raw telemetry data into publishable results is a highly involved. Tracking data sets are becoming larger, and larger as they
are being gathered over longer time periods, over larger spatial extents and at increasing temporal resolutions. While this is increasing our ability
to detect subtle patterns, these data sets are becoming vast and require analytical tools that easily handle, manipulate and visualise these complex
datasets.

Processing and analysing telemetry datasets can require a huge investment in time: rearranging data, removing erroneous values, purchasing,
downloading and learning the new software, and running analyses. Furthermore merging together Excel spreadsheets, filtering data and preparing data
for statistical analyses and plotting in different software packages can introduce all sorts of errors.

**R** is a powerful language for data wrangling and analysis because...

1.  It is relatively **fast** to run and process commands
2.  You can create **repeatable** scripts
3.  You can **trace errors** back to their source
4.  You can **share your scripts** with other people
5.  It is **easy to identify errors** in large data sets
6.  Having your data in **R** opens up a huge array of **cutting edge analysis tools**.
7.  **R** is also totally **FREE!**

As **R** is open source, the more people we can get helping out on the **R** mailing lists (e.g. **R-sig-geo**) and contributing their own packages to
the wider community, the more powerful **R** becomes!

**For this course, we assume you have a basic understanding of the *R* environment, and working with [*RStudio*](https://posit.co/products/open-source/rstudio/)**

<br>

##### 1.1.1 Using R projects

There are a number of good reasons why you should work with Projects in R Studio:

1.  We may want our **R** scripts to be saved into a place where they link seamlessly to other documents and data files for our research project.
2.  We may also want our tables, figures and statistical results to be written to locations on our computer where they are easy to locate.
3.  We may work on multiple workstations (desktops, laptops) that we want our code to be completely transferable using cloud infrastructure 
(e.g. [Dropbox](http://www.dropbox.com/), [OneDrive](https://onedrive.live.com/about/en-au/))
4.  It allows it to share work folders, data and **R** code with collaborators who are working on the same projects

<br>

##### 1.1.2 Installing packages

Part of the reason **R** has become so popular is the vast array of packages that are freely available and highly accessible. In the last few years,
the number of packages has grown exponentially [> 10,000 on CRAN!](http://blog.revolutionanalytics.com/2017/01/cran-10000.html) These can help you to
do a galaxy of different things in **R**, including *running complex analyses*, drawing *beautiful figures*, running *R as a GIS*, constructing
your own *R packages*, building *web pages* and even *writing R course handbooks* like this one!

Let’s suppose you want to load the `sf` package to access this package's incredible spatial functionality. If this package is not already installed 
on your machine, you can download it from the web by using the following command in **R**.

```{r, include=TRUE, eval=FALSE}
install.packages("sf", repos='http://cran.us.r-project.org')
```

In this example, `sf` is the package to be downloaded and 'http://cran.us.r-project.org' is the repository where the package will be accessed from. 

Multiple packages can be loaded at the same time by listing the required packages in a vector... 

``` {r, include=TRUE, eval=FALSE}
install.packages(c("tidyverse",
                   "sf",
                   "ggspatial",
                   "mapview"), repos='http://cran.us.r-project.org')
```


<br>

More recently, package developers have also used other platforms like [**GitHub**](https://github.com) to house **R** packages. This has enabled users 
to access packages that are actively being updated and enable developers to fix problems and develop new features with user feedback.

The `remotes` and `devtools` **R** packages have enabled the installation of packages directly from platforms like **GitHub**. For example, if we want
want to download the `VTrack` package from the github repository, we can use the `install_github()` package to do it like this:

``` {r, include=TRUE, eval=FALSE}
remotes::install_github("rossdwyer/VTrack")
```


<br>

Once installing the packages we want to use, we need to load them using the `library()` function.

```{r, echo=TRUE, eval=FALSE}
library(tidyverse)
library(sf)
library(ggspatial)
library(mapview)
library(VTrack)
```


<br>

------------------------------------------------------------------------------------------------------------------------------------------------------


#### 1.2. Import and explore datasets using %pipes% and the ***tidyverse*** group of R packages

<br>

In this session we are going to work with a data set containing detection data from 3 Australian Blacktip Sharks (*Carcharhinus tilstoni*) shown in the image
above. These animals were captured and tagged within Cleveland Bay, Townsville roughly one month prior to the landfall of Cyclone Yasi in 2011. Blacktip 
sharks were tracked using a network of acoustic hydrophones deployed in a grid pattern on the East and West side of Cleveland Bay. 

Telemetry data from these sharks were analysed alongside 45 others from five species to examine movement patterns of coastal sharks before, during and after 
three extreme weather events in Australia (Cyclone Yasi and Tropical Storm Anthony, 2011) and the US (Tropical Storm Gabrielle, 2001). You can read more about
that study [here](http://www.int-res.com/abstracts/meps/v480/p171-183/).

<br>

```{r, echo=FALSE,message=FALSE,include=TRUE}

library(tidyverse)
library(mapview)
library(leaflet)
library(sf) 

# Import datasets
blacktip <- read_csv('Data/Session 1/Blacktip_ClevelandBay.csv')
statinfo <- read_csv('Data/Session 1/Station_information.csv')

cb <- 
  statinfo %>% 
  filter(installation %in% "Cleveland Bay") %>% 
  group_by(station_name, longitude, latitude) %>% 
  summarise(num_rec = n()) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

bt <-
  blacktip %>% 
  group_by(transmitter_name, station_name, longitude, latitude) %>% 
  summarise(num_det = n()) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

m <- 
    mapview(cb, alpha.reg = 0, alpha = 1, color = "grey", map.types = "Esri.WorldImagery", legend = F, homebutton = F) +
    mapview(bt, zcol = "transmitter_name", burst = T, legend = F, homebutton = F, alpha = 0, alpha.reg = 1)

m@map %>% 
    addLayersControl(
        #baseGroups = c("Map","Satellite"),
        baseGroups = unique(blacktip$transmitter_name),
        options = layersControlOptions(collapsed = FALSE)) %>%
    hideGroup(unique(blacktip$transmitter_name))

```

The web map of detection data we will explore by the end of **Session 1**

<br>

Before we can analyse these data, we first need to read this dataset into R. As with most acoustic detection datasets exported from VUE or other acoustic 
telemetry data management software, our data set is in the 'comma sperated value' (.csv) format. 

A .csv file can simply be imported into **R** using the `read.csv` base function, and by telling R which file to load (`Blacktip_ClevelandBay.csv`) and where
to find it (i.e. in the 'Data' folder).

```{r}
# Load the blacktip shark data using base read.csv function
blacktip <- read.csv('data/Session 1/Blacktip_ClevelandBay.csv', header = TRUE)
```


<br>

In this tutorial, we will also learn how to use the `tidyverse` set of packages. This is becoming an increasingly popular set of packages that share an 
underlying design philosophy, grammar, and data structure. You can learn more about all the features of these packages from the free online course 
developed by the package creators [here](https://r4ds.hadley.nz).


![](images/tidyverse.png)

<br>


The `tidyverse` version of the above code will be `read_csv()` function. The main difference being the data imported as a `tibble` data frame.
The advantage of a `tibble` database is that all the columns will be formatted correctly, with the package guessing what the best format may be.


```{r, message=FALSE}
library(tidyverse)

blacktip <- read_csv('Data/Blacktip_ClevelandBay.csv')

# You can also use fread to input data directly from a website URL
blacktip <- fread('https://raw.githubusercontent.com/RossDwyer/OCS-2018-Rworkshop/master/Data/Blacktip_ClevelandBay.csv')
```

<br>

**A note about Excel files**  

Don’t use '.xlsx' or '.xls' files for saving data. The problem with '.xls' and '.xlsx' files are that they store extra info with the data that makes files larger than necessary and Excel formats can also unwittingly reformat or alter your data! 

A stable way to save your data is as a '.csv' file. These are simply values separated by 'commas' and rows defined by 'returns'. If you select 'Save as’ in Excel, you can choose '.csv' as one of the options. If you open the .csv file provided in the 'Data' folder using a text editor, you will see it is just words, numbers and commas.

<br>



<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


#### 1.3. Working with Spatial objects using the ***sf*** R package


<br>

<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


#### 1.4. Generating interactive maps using ***mapview***


<br>


<br><br><br><br>

------------------------------------------------------------------------------------------------------------------------------------------------------

## Session 2

### Working with satellite telemetry data

|                             |
|:----------------------------|
| ![](Images/whitetip_banner.png) |



<br>

#### 2.1.  Understanding the data structure from satellite tags {.tabset .tabset-fade .tabset-pills}


<br>

##### GPS data



<br>

<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


##### ARGOS data



<br>

<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


##### GLS data


<br>

<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


#### 2.2.  Processing satellite tag data using the *aniMotum* package


<br>

<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


#### 2.3.  Visualising satellite tag data using the *ggspatial* package



<br><br><br><br>

------------------------------------------------------------------------------------------------------------------------------------------------------

## Session 3

### Working with passive acoustic telemetry data

|                         |
|:------------------------|
| ![](images/telemetry.png) |

In this session we will go through a brief walk through of how we can use the *VTrack* R package to quickly format and analyse large acoustic tracking
datasets. A lot of the functions here do similar analyses to the ones you learned in the previous session. We will then go through a new R package
called *re**mo**ra* that helps users to interactively explore thier data as well as append environmental data to detections to further your analysis
of animal movements.

Here we are just arming you with multiple tools to be able to analyse your data. Which analysis (and thus R package) is more appropriate and suitable
to your dataset will depend on your study design, research questions and data available. For this session, we will use the same data you worked on in
session 2, however we will use the ***IMOS Workshop_Bull-shark-sample-dataset*** in the data folder you have downloaded.

<br><br>

#### 3.1.  Understanding the data structure from acoustic telemetry data


<br>


<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


#### 3.2.  Using the *VTrack* R package to explore patterns in animal detections and dispersal



<br>

<br> <br>

------------------------------------------------------------------------------------------------------------------------------------------------------


#### 3.3.  Using the *re**mo**ra* R package to interactively explore your telemetry data


<br>


<br><br><br><br>

------------------------------------------------------------------------------------------------------------------------------------------------------

### Signoff!

This is where we end our R workshop! There may have been a few bits of code that you had trouble with or need more time to work through. We encourage
you to discuss these with us as well as others at the workshop to help get a handle on the R code.

<br>

If you have any comments or queries reguarding this workshop feel free to contact me:

-   Dr. Vinay Udyawer: [v.udyawer\@aims.gov.au](mailto:v.udyawer@aims.gov.au){.email}

**Happy Tracking!**

<br><br><br><br>

------------------------------------------------------------------------------------------------------------------------------------------------------

